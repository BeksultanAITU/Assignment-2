# Assignment 2


## Задача 1. Введение в гетерогенную параллелизацию (теория)

Гетерогенная параллелизация представляет собой подход к организации вычислений, при котором в рамках одной программы используются различные типы вычислительных устройств, чаще всего центральный процессор (CPU) и графический процессор (GPU). Основная идея данного подхода заключается в том, что каждому устройству передаются те задачи, для которых оно наиболее эффективно, что позволяет повысить общую производительность системы.

Архитектура CPU ориентирована на выполнение сложных последовательных операций и задач с большим количеством ветвлений. Центральный процессор содержит ограниченное число мощных ядер, каждое из которых способно эффективно выполнять разнообразные инструкции. Благодаря этому CPU хорошо подходит для управления программой, обработки логики и выполнения задач с высокой степенью зависимости между операциями.

В отличие от CPU, GPU содержит тысячи простых вычислительных ядер и оптимизирован для выполнения большого количества однотипных операций над массивами данных. GPU работает по принципу SIMD (одна инструкция — множество данных), что делает его особенно эффективным для задач численного моделирования, обработки изображений и машинного обучения.

Преимущество гетерогенной параллелизации заключается в более полном использовании аппаратных ресурсов. Такой подход позволяет значительно ускорить вычисления, повысить масштабируемость приложений и добиться лучшей производительности по сравнению с использованием только CPU или только GPU.

Гетерогенные вычисления широко применяются в реальных задачах, включая машинное обучение, компьютерное зрение, физическое и климатическое моделирование, биоинформатику, а также в современных игровых и графических движках.

---

## Задача 2. Работа с массивами и OpenMP

В рамках второй задачи была разработана программа на языке C++, демонстрирующая использование OpenMP для параллельной обработки данных. Программа создаёт массив из 10 000 случайных целых чисел, после чего выполняет поиск минимального и максимального элементов сначала в последовательном режиме, а затем с использованием параллельных директив OpenMP.

Для хранения данных используется контейнер `std::vector<int>`. В последовательной версии алгоритм выполняется в одном потоке, последовательно проходя по всем элементам массива. В параллельной версии используется директива `#pragma omp parallel`, в рамках которой каждый поток вычисляет локальные значения минимума и максимума. Полученные локальные результаты затем объединяются в глобальные значения с использованием критической секции.

Для измерения времени выполнения используется библиотека `std::chrono`. В ряде запусков время выполнения оказывается равным 0 микросекунд, что объясняется малым объёмом данных и высокой скоростью выполнения операций, превышающей разрешающую способность измерений.

Результаты выполнения программы представлены на скриншоте:

![Task 2 Results](Assignment2.png)
![Task 2 Results](2.png)

Анализ результатов показывает, что при небольшом размере массива накладные расходы, связанные с управлением потоками OpenMP, могут нивелировать потенциальный выигрыш в производительности. Однако при увеличении объёма данных параллельная реализация может демонстрировать более высокую эффективность.

---

## Задача 3. Параллельная сортировка выбором с OpenMP

В третьей задаче реализован алгоритм сортировки выбором (Selection Sort) в двух вариантах: последовательном и частично параллельном с использованием OpenMP. Тестирование производительности выполнялось для массивов размером 1 000 и 10 000 элементов.

Алгоритм сортировки выбором имеет выраженные зависимости между итерациями внешнего цикла, поэтому его невозможно полностью распараллелить. В реализованной версии параллелизация применяется только к внутреннему циклу поиска минимального элемента. Для этого каждый поток вычисляет локальный минимум, после чего результаты объединяются в критической секции.

Результаты выполнения и измерения времени представлены на следующем скриншоте:

![Task 3 Results](Assignment2.png)
![Task 3 Results](3.png)

Анализ показывает, что для массива из 1 000 элементов ускорение отсутствует из-за накладных расходов на параллелизацию. Для массива из 10 000 элементов наблюдается уменьшение времени выполнения, однако масштабируемость алгоритма остаётся ограниченной. Это связано с тем, что внешняя часть алгоритма остаётся последовательной, что соответствует закону Амдала.

---

## Контрольные вопросы к Assignment 2

Гетерогенная параллелизация предполагает использование нескольких типов вычислительных устройств в рамках одной программы с целью повышения производительности. Архитектуры CPU и GPU принципиально различаются: CPU ориентирован на управление и сложную логику, тогда как GPU оптимизирован для массовых параллельных вычислений.

Задачи, связанные с обработкой больших массивов данных и выполнением однотипных операций, лучше подходят для GPU, в то время как задачи с ветвлениями и сложной логикой эффективнее выполнять на CPU. Не все алгоритмы хорошо распараллеливаются с использованием OpenMP, поскольку многие из них содержат зависимости между итерациями или требуют использования критических секций.

Основная идея алгоритма сортировки слиянием заключается в рекурсивном разбиении массива на подмассивы, их сортировке и последующем слиянии. При реализации данного алгоритма на GPU возникают сложности, связанные с синхронизацией потоков, управлением памятью и эффективной реализацией параллельного слияния.

Выбор размера блока и сетки в GPU-программах напрямую влияет на степень загрузки вычислительных ресурсов и производительность. Гетерогенный подход позволяет добиться большей эффективности по сравнению с использованием только CPU или только GPU, поскольку каждое устройство применяется для задач, соответствующих его архитектурным особенностям.

---

## Заключение

В ходе выполнения Assignment 2 были изучены основы гетерогенной параллелизации, реализованы и проанализированы параллельные алгоритмы с использованием OpenMP, а также рассмотрены ограничения их масштабируемости. Работа демонстрирует практическое применение теоретических знаний и понимание принципов параллельных вычислений.
