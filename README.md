# Assignment 2  


## Задача 1. Введение в гетерогенную параллелизацию (теория)

### Что такое гетерогенная параллелизация

**Гетерогенная параллелизация** — это подход к организации вычислений, при котором в одной программе одновременно используются **разные типы вычислительных устройств**, чаще всего **CPU и GPU**, каждое из которых выполняет те задачи, для которых оно наиболее эффективно.

---

### Различия между параллельными вычислениями на CPU и GPU

**CPU (Central Processing Unit):**
- Имеет небольшое количество мощных ядер
- Оптимизирован для последовательных и условных операций
- Эффективен для задач с ветвлениями, сложной логикой и управлением
- Хорошо подходит для управления программой и обработки небольших объёмов данных

**GPU (Graphics Processing Unit):**
- Содержит тысячи простых вычислительных ядер
- Оптимизирован для массовых однотипных операций
- Работает по принципу SIMD (одна инструкция — много данных)
- Эффективен для обработки больших массивов данных и численных вычислений

---

### Преимущества гетерогенной параллелизации

- Более эффективное использование аппаратных ресурсов
- Существенное ускорение вычислений для ресурсоёмких задач
- Возможность распределения задач по их природе (логика — CPU, массовые вычисления — GPU)
- Лучшая масштабируемость производительности

---

### Примеры реальных приложений

- Машинное обучение и нейронные сети
- Обработка изображений и видео
- Физическое моделирование и численные симуляции
- Научные расчёты (биоинформатика, климатическое моделирование)
- Игровые движки и графические приложения

---

## Задача 2. Работа с массивами и OpenMP 

### Описание задачи

В рамках данной задачи была реализована программа на C++, которая:

1. Создаёт массив из **10 000 случайных чисел**
2. Находит минимальное и максимальное значения:
   - в последовательной реализации
   - с использованием директив OpenMP
3. Сравнивает время выполнения обеих реализаций и формулирует выводы

---

### Реализация

- Используется `std::vector<int>` для хранения массива
- Последовательный алгоритм выполняется в одном потоке
- Параллельная версия использует директивы `#pragma omp parallel` и `#pragma omp for`
- Каждый поток вычисляет локальные min/max, которые затем объединяются
- Время измеряется с помощью `std::chrono`

---

### Результаты выполнения

Скриншот результата выполнения программы:

![Task 2 Results](Assignment2.png)

---

### Выводы по задаче 2

- Для массива из 10 000 элементов время выполнения слишком мало и может быть округлено до 0 микросекунд
- При небольшом объёме данных накладные расходы OpenMP могут нивелировать ускорение
- Для больших массивов OpenMP может дать выигрыш в производительности

---

## Задача 3. Параллельная сортировка выбором с OpenMP (практика)

### Описание задачи

Реализован алгоритм **сортировки выбором (Selection Sort)**:

- Последовательная версия
- Версия с частичной параллелизацией с использованием OpenMP
- Тестирование на массивах размером **1 000** и **10 000** элементов

---

### Особенности параллелизации

- Внешний цикл сортировки остаётся последовательным
- Внутренний поиск минимального элемента распараллеливается
- Используются локальные минимумы и критическая секция для объединения результатов
- Это демонстрирует ограничения параллелизации алгоритмов с зависимостями

---

### Результаты выполнения

Результаты сортировки и замеры времени представлены на скриншоте:

![Task 3 Results](Assignment2.png)

---

### Выводы по задаче 3

- Для массива из 1 000 элементов ускорение отсутствует из-за накладных расходов
- Для массива из 10 000 элементов наблюдается заметное уменьшение времени
- Сортировка выбором плохо масштабируется из-за последовательного внешнего цикла
- Эффект OpenMP ограничен (закон Амдала)

---

## Задача 4. Сортировка на GPU с использованием CUDA

### Статус выполнения

Данная задача **не реализована программно**.  
Она рассмотрена **теоретически** в рамках контрольных вопросов и общего анализа.

---

## Контрольные вопросы к Assignment 2

### 1. Что понимается под гетерогенной параллелизацией?
Использование нескольких типов вычислительных устройств (CPU, GPU) в одной программе для повышения производительности.

---

### 2. В чём принципиальные различия архитектур CPU и GPU?
CPU оптимизирован для сложной логики и управления, GPU — для массовых параллельных вычислений.

---

### 3. Какие типы задач лучше подходят для GPU, а какие — для CPU?
GPU — задачи с большими массивами данных и однотипными операциями.  
CPU — задачи с ветвлениями, логикой и управлением.

---

### 4. Почему не все алгоритмы эффективно распараллеливаются с OpenMP?
Из-за зависимостей между итерациями, критических секций и последовательных частей алгоритма.

---

### 5. В чём заключается основная идея алгоритма сортировки слиянием?
Рекурсивное разбиение массива на части, их сортировка и последующее слияние.

---

### 6. Какие сложности возникают при реализации сортировки слиянием на GPU?
Синхронизация потоков, управление памятью, эффективное параллельное слияние.

---

### 7. Как выбор размера блока и сетки влияет на производительность GPU?
Он определяет загрузку GPU, использование памяти и степень параллелизма.

---

### 8. Почему гетерогенный подход может быть эффективнее CPU или GPU по отдельности?
Потому что каждая архитектура используется для задач, в которых она наиболее эффективна.

---

